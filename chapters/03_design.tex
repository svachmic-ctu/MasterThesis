\chapter{Design}

\section{System Architecture}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/03_design/design_diagram}
    \caption{Proposed Workflow}
\end{figure}

\subsubsection*{Description}

The workflow should be as linear as possible with respect to the natural flow of data. The central knowledge base is the issue tracker, because that's where the project management team defines objectives set by the top management. The UX team has specific needs for measuring certain tasks in the application so it is absolutely valid that they would add their needs in the issue tracker.

From then on, the domain vocabulary is created and stored for everybody to see. In order to measure the tasks performed by the developer (for example "implement login form") using the same domain vocabulary, something has to deliver a computer-readable version of the vocabulary. That is the task of the Semantic Data Manager - to extract the knowledge from the Issue Tracker and serve it to the developer so he/she can use it easily within the application.

The user data is then reported to the Tracking Engine using the same domain vocabulary that was defined at the beginning. That will enable alignment and easy reporting of the results.

\section{Issue Tracker}

Issue Tracker is a software deployed in a company for managing and tracking the work done by multiple employees across different departments. It serves the project management team to define projects, milestones and to break the work down to tasks and sub-tasks. Those are then assigned to specific people and marked as done when they're done and reviewed. It is considered a good practice that when a task/issue is created and assigned, it becomes immutable with respect to its name (and of course project label and ID). The detailed description and comments can be added, but in order to preserve some stability, the name should remain the same.

There are many solutions on the market, such as Bugzilla, JIRA or open-source Redmine. Most of the solutions provide a REST API for 3rd party integrations.

\subsection{Knowledge structure}

Every company uses a slightly different way of structuring their knowledge in their project management tools. In my situation, the structure is as follows:

\begin{itemize}
	\item Teams
	\item Project
	\item Issues
\end{itemize}

Different tools have different naming conventions, but this structure is as generalized as possible so it is applicable to most of the tools on the market.

\subsubsection{Teams}

Everybody is distributed into teams in various departments. While departments are important in the company structure, in the project management, teams are more relevant. Every team has its own Project Board (either Scrum or Kanban) that reflects the state of the team in time - how much work has been done, what will be done and what's currently being done.

\subsubsection{Projects}

Each team works on their own projects. Often times, collaboration does occur, but the owner of the project is still the team. If other person collaborates with other team, it is reflected in his/her work statistics  (storypoints, hours spent), but the ownership stays within the scope of the project and thus the team as well.

\subsubsection{Issues}

Issue is the most granular entity in the system. It defines a step or set of steps to be performed and is usually assigned to one person. Workflows for reviewing etc. vary from team to team. There is a possibility to break down the work on single issue (if it's especially large one) to sub-tasks, but those are not given IDs, so they are not unique per se. They only serve for clarity and visibility of work being done during the day. When all sub-tasks are finished, the whole issue is finished. That is the state reflected by the API.

\subsection{Knowledge Extraction}

The extraction of the knowledge will build on top of the premise that some parts of the data at certain point of time are immutable. In order to make it as bulletproof as possible, I will only assume immutability of the name of the issue, its automatically assigned identifier (ID) and, obviously, the project it belongs to. Everything else is considered fully mutable and is welcome to be changed in order to provide flexibility.

The idea behind the tracking itself in the same domain vocabulary is that the beginning of an issue/task/sub-task and the end is reported. Giving a direct feedback of success or failure of the implemented workflow.

\subsubsection*{Example}

An issue is created in the Issue Tracker - "Create form for user registration.". The Issue Tracker automatically assigns an identifier, for example "SA-01". The resulting database table should look like this:

\bigbreak

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Issue ID} & \textbf{Name} & \textbf{Type} & \textbf{...} \\
\hline
SA-01 & Form for user registration. & Start & ... \\
\hline
SA-01 & Form for user registration. & Finish & ... \\
\hline
SA-01 & Form for user registration. & Start & ...\\
\hline
SA-01 & Form for user registration. & Finish & ... \\
\hline
SA-01 & Form for user registration. & Start & ...\\
\hline
\end{tabular}
\end{center}
\caption{Example Database Entries}
\label{tab:ex_db}
\end{table}

It is clear what is measured here\footnote{The "..." marks obvious missing columns, such as timestamp, device type etc.} - the success of a registration of a new user. For each commenced registration, there is a "Start" entry. For each successfully finished registration, there is a "Finish" entry. There was not defined any other KPI to measure, so without storing any junk data, it is easy to calculate the percentage ($2/3$) of users that successfully registered versus that didn't ($1/3$).

\subsubsection{DSL}

In order to track more than just the beginning and the end of the workflow defined in the scope of the issue, it is necessary to give the stakeholders a way to define certain observable events to pay attention to. Usually, every issue has a field specifically for description, that contains some human-readable set of instructions. Why not piggyback on that and give it just enough structure to make it also computer-readable?

Let's assume it would be desired, to measure how many times the user clicks on the help button in the registration form. Then the database table would be extended to:

\bigbreak

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Issue ID} & \textbf{Name} & \textbf{Type} & \textbf{...} \\
\hline
SA-01 & Form for user registration. & Start & ... \\
\hline
SA-01 & Form for user registration. & Finish & ... \\
\hline
SA-01 & Help button pressed. & Action & ...\\
\hline
\end{tabular}
\end{center}
\caption{Extended Example Database Entries}
\label{tab:ex_db2}
\end{table}

Another type has appeared in the database table - "Action". Some measurable item, linked to the registration form itself. Neatly labeled with the relevant Issue ID, easy to find and in the same domain vocabulary as was intended.

\section{Semantic Data Manager}

This is the most crucial component of the whole solution - connecting the Issue Tracker and tracking capabilities. The main task is to obtain actionable items from the Issue Tracker and create computer-readable domain vocabularies for application engineers to include in their source code. The computer-readable format should in the for of a configuration file. Therefore, there must be a framework that parses such configuration file, and offers in-code assistance with implementing the tracking itself. It goes without saying that the usage should be as smooth as possible.

The produced configurations should be persisted for the sake of reproducibility. Though it should avoid storing any metadata (detailed measurement description) as it is subject to change (DSL used in the description). Only the unique issue identifier and its name should be persisted, in order to be able to trace back what was the configuration file meant for. Persisting anything else could lead to disconnection between data and that's exactly what I am trying to solve.

Connecting to the Issue Tracker will be handled via its REST API. It should automatically retrieve a list of all projects and their subsequent issues/tasks/sub-tasks that may or may not contain specific metadata regarding fine-grained measurement demands.

Semantic Data Manager will run as a stand-alone microservice and will provide a REST API for any kind of UI to be implemented on top of it. It can easily be a website, mobile application or integration into a 3rd party tool.

\section{Tracking Engine}

The Tracking Engine itself is a completely separate component from the Semantic Data Manager. It can easily be any existing solution - Google Analytics or Google Tag Manager. It should be a stand-alone service into which data is stored using the already obtained domain vocabularies.

For reasons listed in previous chapter, mainly in-house data storage, I will also develop this component and deploy it alongside the Semantic Data Manager. This gives me more flexibility in optimizing the storage and provides the company with a custom tailored solution.

\section{Tracked Device SDK}

The SDK has to have two layers:

\begin{enumerate}
	\item Interpreter of the configuration file from the Semantic Data Manager - load the vocabularies and provide them during the development.
	\item Interface for storing the events - should the Tracking Engine change, the only thing that would be necessary in the application code would be to download dependencies for it and implement the interface. This approach ensures that the in-code measuring always remains the same, only the underlying engine changes.
\end{enumerate}

The whole company runs on iOS devices, so I will develop an iOS framework to be used while developing applications. While iOS may seem limited to only iPhones and iPads, the ecosystem actually enables the frameworks to be written for all Apple platforms - iOS, tvOS and Mac OS X.
